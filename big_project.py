# -*- coding: utf-8 -*-
"""big_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jyt3rf6JP8DU5lBPb6g-sM0pIFrTeoZJ

<a href="https://colab.research.google.com/github/navruzbek1/Datasets/blob/main/bismillah_loyiha1.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import sklearn
import matplotlib.pyplot as plt
# %matplotlib inline

gender=pd.read_csv("/content/gender_submission.csv")
test=pd.read_csv("/content/test.csv")
train=pd.read_csv("/content/train.csv")

gender.info()

train.head()

test.info()

train.info()

train.head()

train.loc[train.Sex=="male","Sex"]=1
train.loc[train.Sex=="female","Sex"]=0

train.drop(["PassengerId","Name","Ticket","Fare","Embarked"],axis=1,inplace=True)

train.head()

train.SibSp.value_counts()

sns.countplot(data=train,x="Survived",)
plt.show()

train.corrwith(train["Survived"]).sort_values(ascending=False)

train.Pclass.value_counts()

549+342



train.Parch.value_counts()

sns.heatmap(train.corr(),cmap='winter',annot=True)
plt.show()

train.corr()

#yuqori korr bor demak,Age->Pclass,Pclass->Survived,Age->SibSp,SibSp->Parch,

sns.pairplot(data=train)

train.head()

train.Parch.value_counts()

train.isnull().sum()

train.isnull().sum()*100/len(train)

def missing_percent(df):
    nan_percent= 100*(df.isnull().sum()/len(df))
    nan_percent= nan_percent[nan_percent>0].sort_values()
    return nan_percent

salom=missing_percent(train)
plt.figure(figsize=(12,6))
sns.barplot(x=salom.index,y=salom)

train.Age=train.Age.fillna(train.Age.median())

train.isnull().sum()

train.drop("Cabin",axis=1,inplace=True)

train.info()

train[["Survived","Pclass"]]=train[["Survived","Pclass"]].astype(dtype="str")

train.info()

train_num=train.select_dtypes(exclude="object")
train_obj=train.select_dtypes(include="object")

train_obj

train_obj.drop("Survived",axis=1,inplace=True)

train_obj=pd.get_dummies(train_obj,drop_first=True)

train.Sex.value_counts()

train_obj

final_train=pd.concat([train_num,train_obj,train["Survived"]],axis=1)

final_train

final_train.shape

x_train=final_train.drop("Survived",axis=1)
y_train=final_train["Survived"]

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.1,random_state=101)

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()

scaler.fit(x_train)

scaled_x_train=scaler.transform(x_train)
scaled_x_test=scaler.transform(x_test)





"""**MODELNI QURAMIZ
**
"""

from sklearn.neighbors import KNeighborsClassifier

knn_model=KNeighborsClassifier(n_neighbors=1)

knn_model.fit(scaled_x_train,y_train)

y_pred=knn_model.predict(scaled_x_test)

pd.DataFrame({"y_test":y_test,"y_pred":y_pred})

y_pred

from sklearn.metrics import classification_report,confusion_matrix,accuracy_score

accuracy_score(y_test,y_pred)

confusion_matrix(y_test,y_pred)

print(classification_report(y_test,y_pred))

test_error_rate=[]



for k in range (1,30):
  knn_model=KNeighborsClassifier(n_neighbors=k)
  knn_model.fit(scaled_x_train,y_train)

  y_pred_test=knn_model.predict(scaled_x_test)  

  test_error=1-accuracy_score(y_test,y_pred_test)
  test_error_rate.append(test_error)

test_error_rate

from sklearn.metrics.pairwise import linear_kernel
plt.figure(figsize=(10,6))
plt.plot(range(1,30),test_error_rate,color="b",linestyle="dashed",marker="o",markerfacecolor="r",markersize=10,label="Test Error")
plt.title("Error Rate and K Value")
plt.ylabel("Error Rate")
plt.xlabel("K Value")
plt.legend()
plt.show()



"""pipeline yaratamiz

"""

scaler=StandardScaler()

knn=KNeighborsClassifier()

knn.get_params().keys()

operations=[("scaler",scaler),("knn",knn)]

from sklearn.pipeline import Pipeline

pipe=Pipeline(operations)

from sklearn.model_selection import GridSearchCV
k_values=list(range(1,20))
param_grid={"knn__n_neighbors": k_values}

full_cv_classifier=GridSearchCV(pipe,param_grid,cv=5,scoring="accuracy")
full_cv_classifier.fit(x_train,y_train)

full_cv_classifier.best_estimator_.get_params()

full_cv_classifier.cv_results_.keys()

scaler= StandardScaler()
knn14= KNeighborsClassifier(n_neighbors=14)
operations= [('scaler', scaler), ('knn14', knn14)]

pipe= Pipeline(operations)

pipe.fit(x_train, y_train)

pipe_pred= pipe.predict(x_test)
y_pred_knn=pipe_pred

print(classification_report(y_test, pipe_pred))

sample= x_test.iloc[44]

sample

sample.values

sample.values.reshape(1, -1)

pipe.predict(sample.values.reshape(1, -1))

pipe.predict_proba(sample.values.reshape(1, -1))